{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kentny/chat-doc/blob/main/Section7/pdf_document_qa_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZlrKuxU6Jtl"
      },
      "source": [
        "# 事前準備\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di8I6XPt53vG"
      },
      "outputs": [],
      "source": [
        "!pip install openai \\\n",
        "           langchain \\\n",
        "           pypdf \\\n",
        "           chromadb \\\n",
        "           tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc8V5M3C8wAD"
      },
      "source": [
        "## OpenAI API Keyを設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DN_a5uYQ6eC1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 定数を設定する"
      ],
      "metadata": {
        "id": "VZlnmdinvSZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用するPDF文書ファイルのパス\n",
        "file_path = '/content/drive/MyDrive/第211回国会衆議院環境委員会第1号令和5年3月7日.pdf'\n",
        "\n",
        "# ベクトルデータベースのパス\n",
        "vectorstore_chroma_path = \"/content/drive/MyDrive/vectorestore/local_chroma\""
      ],
      "metadata": {
        "id": "6KNR99hMvP8m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywzYn19p-iTG"
      },
      "source": [
        "# PDF文書を分析する\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZZI7cT47jWf"
      },
      "source": [
        "## PDF文書を取り込む"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_7rJq9T7lF1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "text_splitter = CharacterTextSplitter(separator='。', chunk_size=100, chunk_overlap=20)\n",
        "docs = loader.load_and_split(text_splitter=text_splitter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea2tsQ3R8BFW"
      },
      "source": [
        "## 文書をベクトル化し、ベクトルデータベースに保存する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVUgOzqMqJ2n"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "if os.path.exists(vectorstore_chroma_path):\n",
        "    shutil.rmtree(vectorstore_chroma_path)\n",
        "    print(\"The database has been deleted.\")\n",
        "else:\n",
        "    print(\"The database does not exist.\")\n",
        "\n",
        "vectordb = Chroma.from_documents(docs, embeddings, persist_directory=vectorstore_chroma_path)\n",
        "vectordb.persist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uDkNuTY-WsE"
      },
      "source": [
        "# 質問から回答を作成する\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G3bP_f8M-VH2"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "def generate_answer(query: str) -> str:\n",
        "    docs = _similarity_search(query)\n",
        "    template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
        "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "    Answer in JAPANESE:\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        template=template, input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "    chain = load_qa_chain(ChatOpenAI(temperature=0.7), prompt=prompt)\n",
        "    \n",
        "    answer = chain.run(input_documents=docs, question=query)\n",
        "    print(f'''answer: {answer}''')\n",
        "    return answer\n",
        "\n",
        "\n",
        "def generate_answer_with_source(query: str) -> str:\n",
        "    docs = _similarity_search(query)\n",
        "    template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
        "    If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
        "    ALWAYS return a \"SOURCES\" part in your answer.\n",
        "    Respond in JAPANESE.\n",
        "\n",
        "    QUESTION: {question}\n",
        "    =========\n",
        "    {summaries}\n",
        "    =========\n",
        "    FINAL ANSWER IN JAPANESE:\"\"\"\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
        "    chain = load_qa_with_sources_chain(ChatOpenAI(temperature=0.7), prompt=prompt)\n",
        "\n",
        "    result = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
        "    answer = result[\"output_text\"]\n",
        "    print(f'''result: {result}''')\n",
        "    print(f'''answer: {answer}''')\n",
        "    return answer\n",
        "\n",
        "\n",
        "def _similarity_search(query: str) -> List[Document]:\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    vectordb = Chroma(persist_directory=vectorstore_chroma_path, embedding_function=embeddings)\n",
        "    return vectordb.similarity_search(query, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw19vk-W_Sef"
      },
      "source": [
        "## 質問をする"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyIugcnQ_AoV"
      },
      "outputs": [],
      "source": [
        "# 質問を入力する\n",
        "question = input()\n",
        "\n",
        "answer = generate_answer(question)\n",
        "print(answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}