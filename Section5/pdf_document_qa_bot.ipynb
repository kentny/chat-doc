{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkXn0lQHdBs4dOfHKlqX/H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kentny/chat-doc/blob/main/Section5/pdf_document_qa_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 事前準備\n",
        "---\n"
      ],
      "metadata": {
        "id": "uZlrKuxU6Jtl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "di8I6XPt53vG"
      },
      "outputs": [],
      "source": [
        "!pip install openai \\\n",
        "           langchain \\\n",
        "           pypdf \\\n",
        "           chromadb \\\n",
        "           tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API Keyを設定"
      ],
      "metadata": {
        "id": "kc8V5M3C8wAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '<YOUR API KEY>'"
      ],
      "metadata": {
        "id": "DN_a5uYQ6eC1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF文書を分析する\n",
        "---"
      ],
      "metadata": {
        "id": "ywzYn19p-iTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PDF文書を取り込む"
      ],
      "metadata": {
        "id": "uZZI7cT47jWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "file_path = '第211回国会衆議院環境委員会第1号令和5年3月7日.pdf'\n",
        "\n",
        "loader = PyPDFLoader(file_path)\n",
        "text_splitter = CharacterTextSplitter(separator='。', chunk_size=100, chunk_overlap=20)\n",
        "docs = loader.load_and_split(text_splitter=text_splitter)"
      ],
      "metadata": {
        "id": "W_7rJq9T7lF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 文書をベクトル化し、ベクトルデータベースに保存する"
      ],
      "metadata": {
        "id": "ea2tsQ3R8BFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "vectorestore_chroma_path = \"./vectorestore/local_chroma\"\n",
        "\n",
        "if os.path.exists(vectorestore_chroma_path):\n",
        "    shutil.rmtree(vectorestore_chroma_path)\n",
        "    print(\"The database has been deleted.\")\n",
        "else:\n",
        "    print(\"The database does not exist.\")\n",
        "\n",
        "vectordb = Chroma.from_documents(docs, embeddings, persist_directory=vectorestore_chroma_path)\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_O7eM4O78DlQ",
        "outputId": "ac738a8f-36cb-4c02-a2a9-e746df50058c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB with persistence: data will be stored in: ./vectorestore/local_chroma\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The database has been deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 質問から回答を作成する\n",
        "---"
      ],
      "metadata": {
        "id": "4uDkNuTY-WsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "\n",
        "def generate_answer(query: str) -> str:\n",
        "    docs = _similarity_search(query)\n",
        "    template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
        "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "    Answer in JAPANESE:\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        template=template, input_variables=[\"context\", \"question\"]\n",
        "    )\n",
        "    chain = load_qa_chain(ChatOpenAI(temperature=0.7), prompt=prompt)\n",
        "    \n",
        "    answer = chain.run(input_documents=docs, question=query)\n",
        "    print(f'''answer: {answer}''')\n",
        "    return answer\n",
        "\n",
        "\n",
        "def generate_answer_with_source(query: str) -> str:\n",
        "    docs = _similarity_search(query)\n",
        "    template = \"\"\"Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
        "    If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
        "    ALWAYS return a \"SOURCES\" part in your answer.\n",
        "    Respond in JAPANESE.\n",
        "\n",
        "    QUESTION: {question}\n",
        "    =========\n",
        "    {summaries}\n",
        "    =========\n",
        "    FINAL ANSWER IN JAPANESE:\"\"\"\n",
        "    prompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])\n",
        "    chain = load_qa_with_sources_chain(ChatOpenAI(temperature=0.7), prompt=prompt)\n",
        "\n",
        "    result = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)\n",
        "    answer = result[\"output_text\"]\n",
        "    print(f'''result: {result}''')\n",
        "    print(f'''answer: {answer}''')\n",
        "    return answer\n",
        "\n",
        "\n",
        "def _similarity_search(query: str) -> List[Document]:\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    vectordb = Chroma(persist_directory=vectorestore_chroma_path, embedding_function=embeddings)\n",
        "    return vectordb.similarity_search(query, 5)"
      ],
      "metadata": {
        "id": "G3bP_f8M-VH2"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 質問をする"
      ],
      "metadata": {
        "id": "Dw19vk-W_Sef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 質問を入力する\n",
        "question = input()\n",
        "\n",
        "answer = generate_answer(question)\n",
        "print(answer)"
      ],
      "metadata": {
        "id": "OyIugcnQ_AoV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}